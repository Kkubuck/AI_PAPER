{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nbox = pd.read_csv('../input/car-object-detection/data/train_solution_bounding_boxes (1).csv')\nbox","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-01T09:40:48.968969Z","iopub.execute_input":"2022-08-01T09:40:48.970113Z","iopub.status.idle":"2022-08-01T09:40:51.076245Z","shell.execute_reply.started":"2022-08-01T09:40:48.969966Z","shell.execute_reply":"2022-08-01T09:40:51.073901Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"sample = cv2.imread('../input/car-object-detection/data/training_images/vid_4_1000.jpg')\nsample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\npoint = box.iloc[0]\npt1 = (int(point['xmin']), int(point['ymax']))\npt2 = (int(point['xmax']), int(point['ymin']))\ncv2.rectangle(sample, pt1, pt2, color = (255, 0, 0), thickness = 2)\nplt.imshow(sample)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:40:51.079762Z","iopub.execute_input":"2022-08-01T09:40:51.080209Z","iopub.status.idle":"2022-08-01T09:40:51.600968Z","shell.execute_reply.started":"2022-08-01T09:40:51.080169Z","shell.execute_reply":"2022-08-01T09:40:51.599819Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"sample = cv2.imread('../input/car-object-detection/data/training_images/vid_4_10040.jpg')\nsample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\npoint = box.iloc[2]\npt1 = (int(point['xmin']), int(point['ymax']))\npt2 = (int(point['xmax']), int(point['ymin']))\ncv2.rectangle(sample, pt1, pt2, color = (255, 0, 0), thickness = 2)\nplt.imshow(sample)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:40:51.602449Z","iopub.execute_input":"2022-08-01T09:40:51.602762Z","iopub.status.idle":"2022-08-01T09:40:51.979184Z","shell.execute_reply.started":"2022-08-01T09:40:51.602732Z","shell.execute_reply":"2022-08-01T09:40:51.978018Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 모델훈련을 위해서는, 데이터셋의 target에 Bounding Box, ImageID, area를 지정해줘야 합니다.\n\n# Explain Dataset\n# Image_ID : 마스크가 속한 이미지 ID\n# area : box의 면적이다. 나중에 예측 Box와 실제 Box의 IoU를 쉽게 구하기 위함이다.\n# iscrowd : 물체가 너무 작은데, 하나의 군집으로 박스를 처리하여, 레이블링 했는지에 관한 여부입니다.\n#           Detection을 하다보면, labeling과 같이 몇가지 주의해야할 기준이 있습니다.\n#          (물체가 숨어있는 경우, 가려져 있는 경우)\n\n\nclass CarDataset(Dataset):\n    def __init__(self, df, image_dir, transforms = None):\n        super().__init__()\n        \n        self.image_ids = df[\"image\"].unique()\n        self.df = df\n        self.image_dir = image_dir\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.image_ids.shape[0]\n    \n    def __getitem__(self, idx : int):\n        image_id = self.image_ids[idx]\n        records = self.df[self.df[\"image\"] == image_id]\n        image = cv2.imread(f\"{self.image_dir}/{image_id}\", cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        image = torch.tensor(image)\n        image = image.permute(2,0,1)\n        \n        boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n        \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        area = torch.as_tensor(area, dtype = torch.float32)\n        \n        labels = torch.ones((records.shape[0]), dtype = torch.int64)\n        \n        target = {}\n        target[\"boxes\"] = torch.tensor(boxes)\n        target[\"labels\"] = labels\n        target[\"image_id\"] = torch.tensor([idx])\n        target[\"area\"] = area\n        \n        if self.transforms:\n            sample = {\"image\" : image, \"boxes\" : target[\"boxes\"], \"labels\" : labels}\n            sample = self.transforms(**sample)\n            image = sample[\"image\"]\n            target[\"boxes\"] = torch.stack(tuple(map(torch.tensor, zip(*sample[\"boxes\"])))).permute(1, 0)\n        \n        return image, target, image_id    ","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:40:51.982533Z","iopub.execute_input":"2022-08-01T09:40:51.982911Z","iopub.status.idle":"2022-08-01T09:40:52.002582Z","shell.execute_reply.started":"2022-08-01T09:40:51.982881Z","shell.execute_reply":"2022-08-01T09:40:52.001263Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ndir_train = \"../input/car-object-detection/data/training_images\"\ntrain_ds = CarDataset(box, dir_train)\n\ntrain_dl = DataLoader(train_ds,batch_size = 8, shuffle = False, num_workers=2, collate_fn = collate_fn)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:40:52.004639Z","iopub.execute_input":"2022-08-01T09:40:52.005734Z","iopub.status.idle":"2022-08-01T09:40:52.016830Z","shell.execute_reply.started":"2022-08-01T09:40:52.005681Z","shell.execute_reply":"2022-08-01T09:40:52.015222Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:40:52.019948Z","iopub.execute_input":"2022-08-01T09:40:52.020302Z","iopub.status.idle":"2022-08-01T09:40:52.079079Z","shell.execute_reply.started":"2022-08-01T09:40:52.020267Z","shell.execute_reply":"2022-08-01T09:40:52.077790Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\n\nmodel = fasterrcnn_resnet50_fpn(pretrained = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:40:52.081314Z","iopub.execute_input":"2022-08-01T09:40:52.082323Z","iopub.status.idle":"2022-08-01T09:41:05.699043Z","shell.execute_reply.started":"2022-08-01T09:40:52.082285Z","shell.execute_reply":"2022-08-01T09:41:05.698004Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"num_classes = 2\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:41:05.700621Z","iopub.execute_input":"2022-08-01T09:41:05.701040Z","iopub.status.idle":"2022-08-01T09:41:05.716887Z","shell.execute_reply.started":"2022-08-01T09:41:05.700979Z","shell.execute_reply":"2022-08-01T09:41:05.716047Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.0005, weight_decay=0.0005)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:41:05.718121Z","iopub.execute_input":"2022-08-01T09:41:05.719519Z","iopub.status.idle":"2022-08-01T09:41:08.617058Z","shell.execute_reply.started":"2022-08-01T09:41:05.719461Z","shell.execute_reply":"2022-08-01T09:41:08.616022Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.train()\n\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    for i, (images, targets, image_ids) in enumerate(train_dl):\n        optimizer.zero_grad()\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        loss_dict = model(images, targets)\n\n        losses = sum(loss for loss in loss_dict.values())\n\n        losses.backward()\n        optimizer.step()\n\n        if (i+1) % 10 == 0:\n            print(f'Epoch {epoch+1} - Total: {losses:.4f}, Regression: {loss_dict[\"loss_box_reg\"]:.4f}, Classifier: {loss_dict[\"loss_classifier\"]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:41:08.620575Z","iopub.execute_input":"2022-08-01T09:41:08.621004Z","iopub.status.idle":"2022-08-01T09:45:38.979981Z","shell.execute_reply.started":"2022-08-01T09:41:08.620963Z","shell.execute_reply":"2022-08-01T09:45:38.978785Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"images = cv2.imread(\"../input/car-object-detection/data/testing_images/vid_5_26640.jpg\", cv2.IMREAD_COLOR)\nimages = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\nimages /= 255.0\nsample = images\nimages = torch.tensor(images)\nimages = images.permute(2,0,1)\nimages = torch.unsqueeze(images, 0)\nimages = images.to(device)\nmodel.eval()\ncpu_device = torch.device(\"cpu\")\n\noutputs = model(images)\noutputs = [{k : v.to(cpu_device) for k, v in t.items()} for t in outputs]\nmask = outputs[0]['scores'] > 0.5\nboxes = outputs[0][\"boxes\"][mask].detach().numpy().astype(np.int32)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:48:45.582201Z","iopub.execute_input":"2022-08-01T09:48:45.582653Z","iopub.status.idle":"2022-08-01T09:48:45.693293Z","shell.execute_reply.started":"2022-08-01T09:48:45.582606Z","shell.execute_reply":"2022-08-01T09:48:45.692077Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nplt.imshow(sample)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:48:56.591073Z","iopub.execute_input":"2022-08-01T09:48:56.591743Z","iopub.status.idle":"2022-08-01T09:48:56.939111Z","shell.execute_reply.started":"2022-08-01T09:48:56.591705Z","shell.execute_reply":"2022-08-01T09:48:56.938049Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"outputs","metadata":{"execution":{"iopub.status.busy":"2022-08-01T09:49:15.076415Z","iopub.execute_input":"2022-08-01T09:49:15.076807Z","iopub.status.idle":"2022-08-01T09:49:15.088565Z","shell.execute_reply.started":"2022-08-01T09:49:15.076776Z","shell.execute_reply":"2022-08-01T09:49:15.087059Z"},"trusted":true},"execution_count":20,"outputs":[]}]}