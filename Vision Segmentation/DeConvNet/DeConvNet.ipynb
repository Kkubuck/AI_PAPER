{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSCkOcC52U71",
        "outputId": "b8838a07-86cc-4f3f-9799-2fec4311f898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch import nn\n",
        "\n",
        "vgg16_pretrained = models.vgg16(pretrained = False)\n",
        "\n",
        "def decoder(input_channel, output_channel, num = 3):\n",
        "    if num == 3:\n",
        "        decoder_body = nn.Sequential(\n",
        "            nn.ConvTranspose2d(input_channel, input_channel, 3, padding = 1),\n",
        "            nn.ConvTranspose2d(input_channel, input_channel, 3, padding = 1),\n",
        "            nn.ConvTranspose2d(input_channel, output_channel, 3, padding = 1)\n",
        "        )\n",
        "    \n",
        "    elif num == 2:\n",
        "        decoder_body = nn.Sequential(\n",
        "            nn.ConvTranspose2d(input_channel, input_channel, 3, padding = 1),\n",
        "            nn.ConvTranspose2d(input_channel, output_channel, 3, padding = 1)\n",
        "        )\n",
        "\n",
        "    \n",
        "    return decoder_body"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unpooling 과 DeConvolution의 차이\n",
        "\n",
        "- Unpooling : 이미지 공간으로의 강한 Activation의 위치를 추적함으로써, 관련된 예시들을 더 잘아내는 역할을 수행함.\n",
        "\n",
        "- Deconvolution : 원본 이미지 내의 noisy activatian을 잘 걸러내며, target과 관련된 부분의 활성화를 증폭함."
      ],
      "metadata": {
        "id": "n-EX29R7BKAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16_deconv(torch.nn.Module):\n",
        "    def __init__(self, num_classes = 8, num_linear = 131072, channel = 512, height = 16, width = 16):\n",
        "        super(VGG16_deconv, self).__init__()\n",
        "        self.channel = channel\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "        pool_list = [4, 9, 16, 23, 30]\n",
        "\n",
        "        for index in pool_list:\n",
        "            vgg16_pretrained.features[index].return_indices = True\n",
        "        \n",
        "        self.encoder1 = vgg16_pretrained.features[:4]\n",
        "        self.pool1 = vgg16_pretrained.features[4]\n",
        "\n",
        "        self.encoder2 = vgg16_pretrained.features[5:9]\n",
        "        self.pool2 = vgg16_pretrained.features[9]\n",
        "\n",
        "        self.encoder3 = vgg16_pretrained.features[10:16]\n",
        "        self.pool3 = vgg16_pretrained.features[16]\n",
        "\n",
        "        self.encoder4 = vgg16_pretrained.features[17:23]\n",
        "        self.pool4 = vgg16_pretrained.features[23]\n",
        "\n",
        "        self.encoder5 = vgg16_pretrained.features[24: 30]\n",
        "        self.pool5 = vgg16_pretrained.features[30]\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            torch.nn.Linear(num_linear, 4096),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(4096, num_linear),\n",
        "            torch.nn.ReLU()\n",
        "        ) \n",
        "\n",
        "        self.decoder5 = decoder(512, 512)\n",
        "        self.unpool5 = nn.MaxUnpool2d(2, 2)\n",
        "        \n",
        "        self.decoder4 = decoder(512, 256)\n",
        "        self.unpool4 = nn.MaxUnpool2d(2, 2)\n",
        "        \n",
        "        self.decoder3 = decoder(256, 128)\n",
        "        self.unpool3 = nn.MaxUnpool2d(2, 2)\n",
        "\n",
        "        self.decoder2 = decoder(128, 64, 2)\n",
        "        self.unpool2 = nn.MaxUnpool2d(2, 2)\n",
        "\n",
        "        self.decoder1 = decoder(64, num_classes, 2)\n",
        "        self.unpool1 = nn.MaxUnpool2d(2, 2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        print('x size:', x.size())\n",
        "\n",
        "        encoder1 = self.encoder1(x)\n",
        "        print('encoder1 size: ', encoder1.size())\n",
        "        output_size1 = encoder1.size()        \n",
        "        pool1, indices1 = self.pool1(encoder1)\n",
        "        print('pool1 size: ', pool1.size(), 'indices1 size : ', indices1.size())\n",
        "\n",
        "        encoder2 = self.encoder2(pool1)\n",
        "        print('encoder2 size :', encoder2.size())\n",
        "        output_size2 = encoder2.size()\n",
        "        pool2, indices2 = self.pool2(encoder2)\n",
        "        print('pool2 size : ', pool2.size() ,'indices2 size : ', indices2.size())\n",
        "\n",
        "        encoder3 = self.encoder3(pool2)\n",
        "        print('encoder3 size : ', encoder3.size())\n",
        "        output_size3 = encoder3.size()\n",
        "        pool3, indices3 = self.pool3(encoder3)\n",
        "        print('pool3 size : ', pool3.size(), 'indices3 size : ', indices3.size())\n",
        "\n",
        "        encoder4 = self.encoder4(pool3)\n",
        "        print('encoder4 size : ', encoder4.size())\n",
        "        output_size4 = encoder4.size()\n",
        "        pool4, indices4 = self.pool4(encoder4)\n",
        "        print('pool4 size : ', pool4.size(), 'indices4 size : ', indices4.size())\n",
        "\n",
        "        encoder5 = self.encoder5(pool4)\n",
        "        print('encoder5 size : ', encoder5.size())\n",
        "        output_size5 = encoder5.size()\n",
        "        pool5, indices5 = self.pool5(encoder5)\n",
        "        print('pool5 size : ', pool5.size(), 'indices5 size : ', indices5.size())\n",
        "\n",
        "\n",
        "        pool5 = pool5.view(pool5.size(0), -1)\n",
        "        print('pool5 : ', pool5.size())\n",
        "        fc = self.classifier(pool5)\n",
        "        print('fc :', fc.size())\n",
        "        fc = fc.reshape(1, self.channel, self.height, self.width)\n",
        "        print('fc : ', fc.size())\n",
        "\n",
        "        unpool5 = self.unpool5(input = fc, indices = indices5, output_size = output_size5)\n",
        "        print('unpool5 : ', unpool5.size())\n",
        "        decoder5 = self.decoder5(unpool5)\n",
        "        print('decoder 5 : ', decoder5.size())\n",
        "\n",
        "        unpool4 = self.unpool4(input = decoder5, indices = indices4, output_size = output_size4)\n",
        "        print('unpool4 : ', unpool4.size())\n",
        "        decoder4 = self.decoder4(unpool4)\n",
        "        print('decoder 4 : ', decoder4.size())\n",
        "\n",
        "        unpool3 = self.unpool3(input = decoder4, indices = indices3, output_size = output_size3)\n",
        "        print('unpool3 : ', unpool3.size())\n",
        "        decoder3 = self.decoder3(unpool3)\n",
        "        print('decoder 3 : ', decoder3.size())\n",
        "\n",
        "        unpool2 = self.unpool2(input = decoder3, indices = indices2, output_size = output_size2)\n",
        "        print('unpool2 : ', unpool2.size())\n",
        "        decoder2 = self.decoder2(unpool2)\n",
        "        print('deocder 2 : ', decoder2.size())\n",
        "\n",
        "        unpool1 = self.unpool1(input = decoder2, indices = indices1, output_size = output_size1)\n",
        "        print('unpool1 : ', unpool1.size())\n",
        "        decoder1 = self.decoder1(unpool1)\n",
        "        print('decoder 1 : ', decoder1.size())\n",
        "\n",
        "        return decoder1 \n"
      ],
      "metadata": {
        "id": "agycfq4v5YFX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.zeros(1, 3, 512, 512)\n",
        "DeConvNet = VGG16_deconv(num_classes = 8, num_linear = 131072, channel = 512, height = 16, width = 16)\n",
        "zz = DeConvNet(temp)\n",
        "zz.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TSIDZYZ7JL4",
        "outputId": "cbada1b4-79ab-4882-c15f-98dad7440c1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x size: torch.Size([1, 3, 512, 512])\n",
            "encoder1 size:  torch.Size([1, 64, 512, 512])\n",
            "pool1 size:  torch.Size([1, 64, 256, 256]) indices1 size :  torch.Size([1, 64, 256, 256])\n",
            "encoder2 size : torch.Size([1, 128, 256, 256])\n",
            "pool2 size :  torch.Size([1, 128, 128, 128]) indices2 size :  torch.Size([1, 128, 128, 128])\n",
            "encoder3 size :  torch.Size([1, 256, 128, 128])\n",
            "pool3 size :  torch.Size([1, 256, 64, 64]) indices3 size :  torch.Size([1, 256, 64, 64])\n",
            "encoder4 size :  torch.Size([1, 512, 64, 64])\n",
            "pool4 size :  torch.Size([1, 512, 32, 32]) indices4 size :  torch.Size([1, 512, 32, 32])\n",
            "encoder5 size :  torch.Size([1, 512, 32, 32])\n",
            "pool5 size :  torch.Size([1, 512, 16, 16]) indices5 size :  torch.Size([1, 512, 16, 16])\n",
            "pool5 :  torch.Size([1, 131072])\n",
            "fc : torch.Size([1, 131072])\n",
            "fc :  torch.Size([1, 512, 16, 16])\n",
            "unpool5 :  torch.Size([1, 512, 32, 32])\n",
            "decoder 5 :  torch.Size([1, 512, 32, 32])\n",
            "unpool4 :  torch.Size([1, 512, 64, 64])\n",
            "decoder 4 :  torch.Size([1, 256, 64, 64])\n",
            "unpool3 :  torch.Size([1, 256, 128, 128])\n",
            "decoder 3 :  torch.Size([1, 128, 128, 128])\n",
            "unpool2 :  torch.Size([1, 128, 256, 256])\n",
            "deocder 2 :  torch.Size([1, 64, 256, 256])\n",
            "unpool1 :  torch.Size([1, 64, 512, 512])\n",
            "decoder 1 :  torch.Size([1, 8, 512, 512])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 512, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTs_zd8vIHUk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}